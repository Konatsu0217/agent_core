# Agent èŒƒå¼æ·±åº¦è§£æï¼šä» ReAct åˆ°å®æˆ˜

## ğŸ“– ç›®å½•
1. [ä»€ä¹ˆæ˜¯ Agentï¼Ÿ](#ä»€ä¹ˆæ˜¯-agent)
2. [æ ¸å¿ƒèŒƒå¼å¯¹æ¯”](#æ ¸å¿ƒèŒƒå¼å¯¹æ¯”)
3. [ReAct æ·±åº¦è§£æ](#react-æ·±åº¦è§£æ)
4. [å…¶ä»–ä¸»æµèŒƒå¼](#å…¶ä»–ä¸»æµèŒƒå¼)
5. [å¦‚ä½•é€‰æ‹©èŒƒå¼](#å¦‚ä½•é€‰æ‹©èŒƒå¼)
6. [åœ¨ä½ çš„ Agent Core ä¸­åº”ç”¨](#åœ¨ä½ çš„-agent-core-ä¸­åº”ç”¨)

---

## ğŸ¤– ä»€ä¹ˆæ˜¯ Agentï¼Ÿ

### å®šä¹‰
**Agent** = LLM + Planning + Tools + Memory

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Agent                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   LLM    â”‚   â”‚   Planning   â”‚   â”‚
â”‚  â”‚  (å¤§è„‘)  â”‚â—„â”€â”€â”¤  (å†³ç­–å¼•æ“)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚        â”‚                            â”‚
â”‚        â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Tools   â”‚   â”‚    Memory    â”‚   â”‚
â”‚  â”‚  (å·¥å…·)  â”‚   â”‚   (è®°å¿†)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸æ™®é€š LLM è°ƒç”¨çš„åŒºåˆ«

| ç‰¹æ€§ | æ™®é€š LLM | Agent |
|------|---------|-------|
| äº¤äº’æ–¹å¼ | å•æ¬¡é—®ç­” | å¤šè½®æ¨ç† |
| å·¥å…·ä½¿ç”¨ | æ—  | å¯è°ƒç”¨å¤–éƒ¨å·¥å…· |
| å†³ç­–èƒ½åŠ› | æ—  | è‡ªä¸»è§„åˆ’æ­¥éª¤ |
| å¤æ‚ä»»åŠ¡ | éš¾ä»¥å¤„ç† | åˆ†æ­¥è§£å†³ |

**ç¤ºä¾‹å¯¹æ¯”**:
```
âŒ æ™®é€š LLM:
User: "å¸®æˆ‘è®¢æ˜å¤©å»ä¸Šæµ·çš„æœºç¥¨"
LLM: "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç›´æ¥è®¢ç¥¨ï¼Œä½ å¯ä»¥å»æºç¨‹..."

âœ… Agent:
User: "å¸®æˆ‘è®¢æ˜å¤©å»ä¸Šæµ·çš„æœºç¥¨"
Agent Thought: æˆ‘éœ€è¦å…ˆæŸ¥è¯¢èˆªç­ä¿¡æ¯
Agent Action: search_flights(from="åŒ—äº¬", to="ä¸Šæµ·", date="2024-01-15")
Agent Observation: [èˆªç­åˆ—è¡¨]
Agent Thought: ç”¨æˆ·æœªæŒ‡å®šåå¥½ï¼Œæˆ‘åº”è¯¥è¯¢é—®
Agent: "æ‰¾åˆ°3ä¸ªèˆªç­ï¼Œä½ åå¥½æ—©ç­æœºè¿˜æ˜¯æ™šç­æœºï¼Ÿ"
```

---

## ğŸ­ æ ¸å¿ƒèŒƒå¼å¯¹æ¯”

### èŒƒå¼å…¨æ™¯å›¾

```
Agent èŒƒå¼
â”œâ”€â”€ Chain-based (é“¾å¼)
â”‚   â”œâ”€â”€ Simple Chain: A â†’ B â†’ C
â”‚   â””â”€â”€ Sequential Chain: å›ºå®šæ­¥éª¤åºåˆ—
â”‚
â”œâ”€â”€ ReAct (æ¨ç†-è¡ŒåŠ¨)
â”‚   â”œâ”€â”€ Zero-shot ReAct: LLM è‡ªä¸»å†³ç­–æ¯ä¸€æ­¥
â”‚   â””â”€â”€ Few-shot ReAct: æä¾›ç¤ºä¾‹å¼•å¯¼
â”‚
â”œâ”€â”€ Plan-and-Execute (å…ˆè§„åˆ’åæ‰§è¡Œ)
â”‚   â”œâ”€â”€ Planning: ç”Ÿæˆå®Œæ•´è®¡åˆ’
â”‚   â””â”€â”€ Execution: æŒ‰è®¡åˆ’æ‰§è¡Œ
â”‚
â”œâ”€â”€ Reflexion (åæ€)
â”‚   â”œâ”€â”€ Execute: æ‰§è¡Œä»»åŠ¡
â”‚   â”œâ”€â”€ Reflect: åæ€ç»“æœ
â”‚   â””â”€â”€ Refine: æ”¹è¿›è®¡åˆ’
â”‚
â””â”€â”€ Tree-based (æ ‘çŠ¶æœç´¢)
    â”œâ”€â”€ Tree of Thoughts: æ¢ç´¢å¤šæ¡è·¯å¾„
    â””â”€â”€ Best-first Search: ä¼˜å…ˆæœ€ä¼˜è·¯å¾„
```

---

## ğŸ”¥ ReAct æ·±åº¦è§£æ

### æ ¸å¿ƒæ€æƒ³

**ReAct** = **Re**asoning (æ¨ç†) + **Act**ing (è¡ŒåŠ¨)

LLM é€šè¿‡äº¤æ›¿è¿›è¡Œ"æ€è€ƒ"å’Œ"è¡ŒåŠ¨"æ¥è§£å†³å¤æ‚ä»»åŠ¡ã€‚

### å®Œæ•´æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            ReAct å¾ªç¯                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Thought (æ€è€ƒ)  â”‚ â† LLM åˆ†æå½“å‰çŠ¶æ€
    â”‚ "æˆ‘éœ€è¦å…ˆæŸ¥å¤©æ°”" â”‚    å†³å®šä¸‹ä¸€æ­¥åšä»€ä¹ˆ
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Action (è¡ŒåŠ¨)   â”‚ â† è°ƒç”¨å…·ä½“å·¥å…·
    â”‚ search_weather() â”‚    æ‰§è¡Œæ“ä½œ
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Observation(è§‚å¯Ÿ) â”‚ â† è·å–å·¥å…·è¿”å›ç»“æœ
    â”‚ "ä»Šå¤©25Â°Cæ™´"     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
         æ˜¯å¦å®Œæˆ? â”€â”€Noâ”€â”€â”
             â”‚           â”‚
            Yes          â”‚
             â”‚           â”‚
             â–¼           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
         â”‚ Answer â”‚     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                        â”‚
         â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        (å›åˆ° Thought)
```

### è¯¦ç»†ç¤ºä¾‹

**ä»»åŠ¡**: "æ˜å¤©åŒ—äº¬é€‚åˆæˆ·å¤–è¿åŠ¨å—ï¼Ÿ"

```
=== ç¬¬ 1 è½® ===

Thought 1: è¦åˆ¤æ–­æ˜¯å¦é€‚åˆæˆ·å¤–è¿åŠ¨ï¼Œæˆ‘éœ€è¦å…ˆçŸ¥é“æ˜å¤©åŒ—äº¬çš„å¤©æ°”æƒ…å†µï¼Œ
           åŒ…æ‹¬æ¸©åº¦ã€é™æ°´å’Œé£åŠ›ã€‚

Action 1: search_weather(city="åŒ—äº¬", date="tomorrow")

Observation 1: {
  "temperature": "18-25Â°C",
  "weather": "å¤šäº‘",
  "wind": "3çº§",
  "precipitation": "10%"
}

=== ç¬¬ 2 è½® ===

Thought 2: å¤©æ°”æ•°æ®æ˜¾ç¤ºæ˜å¤©å¤šäº‘ï¼Œæ¸©åº¦é€‚å®œï¼Œé£åŠ›è¾ƒå°ï¼Œé™æ°´æ¦‚ç‡ä½ã€‚
           ä½†æˆ‘è¿˜éœ€è¦è€ƒè™‘ç©ºæ°”è´¨é‡ï¼Œè¿™å¯¹æˆ·å¤–è¿åŠ¨å¾ˆé‡è¦ã€‚

Action 2: get_air_quality(city="åŒ—äº¬", date="tomorrow")

Observation 2: {
  "aqi": 85,
  "level": "è‰¯",
  "pm25": 60
}

=== ç¬¬ 3 è½® ===

Thought 3: ç©ºæ°”è´¨é‡ä¸ºè‰¯ï¼ŒAQI 85ï¼Œè™½ç„¶ä¸æ˜¯ä¼˜ä½†å¯ä»¥æ¥å—ã€‚
           ç°åœ¨æˆ‘æœ‰è¶³å¤Ÿä¿¡æ¯ç»™å‡ºå»ºè®®äº†ã€‚

Answer: æ˜å¤©åŒ—äº¬çš„å¤©æ°”æ¡ä»¶æ€»ä½“é€‚åˆæˆ·å¤–è¿åŠ¨ï¼š
        - æ¸©åº¦ 18-25Â°Cï¼Œä½“æ„Ÿèˆ’é€‚
        - å¤šäº‘å¤©æ°”ï¼Œä¸ä¼šå¤ªçƒ­
        - é£åŠ› 3 çº§ï¼Œè¾ƒä¸ºå¹³ç¼“
        - é™æ°´æ¦‚ç‡ä»… 10%
        - ç©ºæ°”è´¨é‡ä¸ºè‰¯ï¼ˆAQI 85ï¼‰
        
        å»ºè®®åœ¨ä¸Šåˆæˆ–å‚æ™šè¿›è¡Œæˆ·å¤–æ´»åŠ¨ï¼Œé¿å¼€ä¸­åˆæ—¶æ®µã€‚
```

### ReAct Prompt è®¾è®¡

**æ ‡å‡† Prompt æ¨¡æ¿**:
```
You run in a loop of Thought, Action, Observation.
At the end of the loop you output an Answer.

Use Thought to describe your thinking about the question.
Use Action to run one of the actions available to you.
Observation will be the result of running those actions.

Available actions:
- search_weather(city: str, date: str): Get weather information
- get_air_quality(city: str): Get air quality index

Example:
Question: What's the weather in Beijing?
Thought: I need to search for Beijing's weather
Action: search_weather(city="Beijing", date="today")
Observation: Temperature: 25Â°C, Sunny
Thought: I now have the weather information
Answer: The weather in Beijing is sunny, 25Â°C

Now solve this:
Question: {user_question}
```

### OpenAI Function Calling çš„ ReAct ç®€åŒ–ç‰ˆ

OpenAI çš„ Function Calling **éšè—äº†æ˜¾å¼çš„ Thought**ï¼Œç›´æ¥è¿”å› Actionï¼š

```python
# ä¼ ç»Ÿ ReAct éœ€è¦è§£ææ–‡æœ¬
response = """
Thought: I need to check weather
Action: search_weather(city="Beijing")
"""

# OpenAI Function Calling ç›´æ¥è¿”å›ç»“æ„åŒ–
response = {
  "tool_calls": [{
    "function": {
      "name": "search_weather",
      "arguments": '{"city": "Beijing"}'
    }
  }]
}
```

**å¯¹æ¯”**:
| ç‰¹æ€§ | ä¼ ç»Ÿ ReAct | Function Calling |
|------|-----------|------------------|
| æ€è€ƒè¿‡ç¨‹ | æ˜¾å¼ï¼ˆThoughtï¼‰ | éšå¼ï¼ˆå†…éƒ¨æ¨ç†ï¼‰ |
| è¾“å‡ºæ ¼å¼ | æ–‡æœ¬è§£æ | ç»“æ„åŒ– JSON |
| å¯é æ€§ | ä¾èµ– prompt | API ä¿è¯æ ¼å¼ |
| å¯è§£é‡Šæ€§ | é«˜ï¼ˆèƒ½çœ‹åˆ°æ€è€ƒï¼‰ | ä½ï¼ˆé»‘ç›’ï¼‰ |

---

## ğŸŒŸ å…¶ä»–ä¸»æµèŒƒå¼

### 1. Plan-and-Execute (å…ˆè§„åˆ’åæ‰§è¡Œ)

**æ ¸å¿ƒæ€æƒ³**: å…ˆç”¨ LLM ç”Ÿæˆå®Œæ•´è®¡åˆ’ï¼Œå†æŒ‰è®¡åˆ’æ‰§è¡Œ

**æµç¨‹**:
```
Step 1: Planning Phase
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User: "å¸®æˆ‘å‡†å¤‡æ˜å¤©çš„ä¼šè®®"        â”‚
â”‚                                  â”‚
â”‚ LLM Planning:                    â”‚
â”‚ 1. æŸ¥è¯¢æ—¥å†ç¡®è®¤ä¼šè®®æ—¶é—´           â”‚
â”‚ 2. æ£€æŸ¥å‚ä¼šäººå‘˜åå•               â”‚
â”‚ 3. å‡†å¤‡ä¼šè®®èµ„æ–™                  â”‚
â”‚ 4. å‘é€ä¼šè®®æé†’                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Execution Phase
æ‰§è¡Œæ¯ä¸ªæ­¥éª¤ â†’ æ”¶é›†ç»“æœ â†’ æ±‡æ€»åé¦ˆ
```

**é€‚ç”¨åœºæ™¯**:
- âœ… å¤šæ­¥éª¤ä»»åŠ¡éœ€è¦æ•´ä½“ä¼˜åŒ–
- âœ… æ­¥éª¤ä¹‹é—´æœ‰ä¾èµ–å…³ç³»
- âŒ ä»»åŠ¡åŠ¨æ€æ€§å¼ºï¼ˆè®¡åˆ’å®¹æ˜“å¤±æ•ˆï¼‰

**ä»£ç ç¤ºä¾‹**:
```python
async def plan_and_execute(query: str):
    # Phase 1: Planning
    plan_prompt = f"""
    Create a step-by-step plan to accomplish:
    {query}
    
    Return as JSON: {{"steps": ["step1", "step2", ...]}}
    """
    plan = await llm.chat(plan_prompt)
    steps = json.loads(plan)["steps"]
    
    # Phase 2: Execution
    results = []
    for step in steps:
        result = await execute_step(step)
        results.append(result)
    
    # Phase 3: Synthesis
    return synthesize_results(results)
```

---

### 2. Reflexion (åæ€)

**æ ¸å¿ƒæ€æƒ³**: æ‰§è¡Œ â†’ è¯„ä¼° â†’ åæ€ â†’ æ”¹è¿›

**æµç¨‹**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Execute   â”‚ â†’ æ‰§è¡Œä»»åŠ¡
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Evaluate  â”‚ â†’ è¯„ä¼°ç»“æœè´¨é‡
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Reflect   â”‚ â†’ åˆ†æå¤±è´¥åŸå› 
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Refine    â”‚ â†’ æ”¹è¿›ç­–ç•¥
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€â”€â”€â”€â”€â”€â–º é‡æ–°æ‰§è¡Œ
```

**å®Œæ•´ç¤ºä¾‹**:

```
Task: å†™ä¸€ä¸ª Python æ’åºå‡½æ•°

=== Iteration 1 ===
Execute: 
def sort(arr):
    return sorted(arr)

Evaluate: å¤ªç®€å•äº†ï¼Œæ²¡æœ‰å±•ç¤ºç®—æ³•ç†è§£

Reflect: 
- æˆ‘ç›´æ¥ç”¨äº†å†…ç½®å‡½æ•°
- åº”è¯¥å®ç°ä¸€ä¸ªç»å…¸æ’åºç®—æ³•
- ç”¨æˆ·å¯èƒ½æƒ³çœ‹ç®—æ³•ç»†èŠ‚

Refine: é‡å†™ä¸ºå¿«é€Ÿæ’åºå®ç°

=== Iteration 2 ===
Execute:
def quicksort(arr):
    if len(arr) <= 1: return arr
    pivot = arr[0]
    left = [x for x in arr[1:] if x < pivot]
    right = [x for x in arr[1:] if x >= pivot]
    return quicksort(left) + [pivot] + quicksort(right)

Evaluate: ç®—æ³•æ­£ç¡®ï¼Œä½†æ•ˆç‡å¯ä»¥ä¼˜åŒ–

Reflect:
- é€‰æ‹©ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸º pivot åœ¨æœ€åæƒ…å†µä¸‹æ˜¯ O(nÂ²)
- åº”è¯¥ä½¿ç”¨éšæœº pivot

Refine: æ·»åŠ éšæœº pivot é€‰æ‹©

=== Final Result ===
(ä¼˜åŒ–åçš„å¿«é€Ÿæ’åºå®ç°)
```

**é€‚ç”¨åœºæ™¯**:
- âœ… éœ€è¦é«˜è´¨é‡è¾“å‡ºï¼ˆä»£ç ç”Ÿæˆã€å†™ä½œï¼‰
- âœ… æœ‰æ˜ç¡®è¯„ä¼°æ ‡å‡†
- âŒ ç®€å•ä»»åŠ¡ï¼ˆåæ€æˆæœ¬é«˜ï¼‰

---

### 3. Tree of Thoughts (æ€ç»´æ ‘)

**æ ¸å¿ƒæ€æƒ³**: æ¢ç´¢å¤šæ¡æ¨ç†è·¯å¾„ï¼Œé€‰æ‹©æœ€ä¼˜è§£

```
                  æ ¹é—®é¢˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼           â–¼           â–¼
      è·¯å¾„A        è·¯å¾„B        è·¯å¾„C
        â”‚           â”‚           â”‚
    â”Œâ”€â”€â”€â”¼â”€â”€â”€â”   â”Œâ”€â”€â”€â”¼â”€â”€â”€â”   â”Œâ”€â”€â”€â”¼â”€â”€â”€â”
    â–¼   â–¼   â–¼   â–¼   â–¼   â–¼   â–¼   â–¼   â–¼
   A1  A2  A3  B1  B2  B3  C1  C2  C3
   
   è¯„ä¼°æ¯æ¡è·¯å¾„ï¼Œé€‰æ‹©æœ€ä¼˜
```

**ç¤ºä¾‹**: è§£æ•°å­¦é¢˜

```
é—®é¢˜: 24 ç‚¹æ¸¸æˆ (4, 7, 8, 8) â†’ 24

æ¢ç´¢è·¯å¾„:
Path A: (8 - 4) * (7 - 8) = 4 * (-1) = -4 âŒ
Path B: (8 Ã· 8) * (7 * 4) = 1 * 28 = 28 âŒ
Path C: (8 - 4 + 7) * 8 = 11 * 8 = 88 âŒ
Path D: (8 - 7 + 4) * 8 = 5 * 8 = 40 âŒ
Path E: 8 Ã· (4 - 8 Ã· 7) = ? (è®¡ç®—å¤æ‚) æš‚åœ
Path F: (7 - 8 Ã· 8) * 4 = (7 - 1) * 4 = 24 âœ…

é€‰æ‹© Path F
```

**é€‚ç”¨åœºæ™¯**:
- âœ… åˆ›æ„ä»»åŠ¡ï¼ˆéœ€è¦æ¢ç´¢å¤šç§æ–¹æ¡ˆï¼‰
- âœ… å†³ç­–ä¼˜åŒ–ï¼ˆé€‰æ‹©æœ€ä¼˜è·¯å¾„ï¼‰
- âŒ Token æ¶ˆè€—å¤§ï¼ˆæ¢ç´¢å¤šæ¡è·¯å¾„ï¼‰

---

## ğŸ¯ å¦‚ä½•é€‰æ‹©èŒƒå¼

### å†³ç­–æ ‘

```
ä½ çš„ä»»åŠ¡æ˜¯...

â”œâ”€ å•æ­¥ç®€å•ä»»åŠ¡
â”‚  â””â”€ ç”¨æ™®é€š LLM è°ƒç”¨å³å¯
â”‚
â”œâ”€ éœ€è¦å·¥å…·è°ƒç”¨çš„ä»»åŠ¡
â”‚  â”œâ”€ æ­¥éª¤å›ºå®šã€æµç¨‹æ¸…æ™°
â”‚  â”‚  â””â”€ ä½¿ç”¨ Chain (é“¾å¼)
â”‚  â”‚
â”‚  â”œâ”€ æ­¥éª¤ä¸ç¡®å®šï¼Œéœ€è¦åŠ¨æ€å†³ç­–
â”‚  â”‚  â””â”€ ä½¿ç”¨ ReAct â­ æœ€å¸¸ç”¨
â”‚  â”‚
â”‚  â””â”€ å¤æ‚å¤šæ­¥éª¤ï¼Œéœ€è¦æ•´ä½“ä¼˜åŒ–
â”‚     â””â”€ ä½¿ç”¨ Plan-and-Execute
â”‚
â”œâ”€ éœ€è¦é«˜è´¨é‡è¾“å‡º
â”‚  â””â”€ ä½¿ç”¨ Reflexion (è¿­ä»£æ”¹è¿›)
â”‚
â””â”€ éœ€è¦æ¢ç´¢å¤šç§æ–¹æ¡ˆ
   â””â”€ ä½¿ç”¨ Tree of Thoughts
```

### èŒƒå¼å¯¹æ¯”è¡¨

| èŒƒå¼ | ä¼˜åŠ¿ | åŠ£åŠ¿ | Token æ¶ˆè€— | é€‚ç”¨åœºæ™¯ |
|------|------|------|-----------|---------|
| **ReAct** | çµæ´»ã€å¯è§£é‡Šã€é€šç”¨ | å¯èƒ½ç»•è·¯ | ä¸­ç­‰ | ğŸŒŸ **é€šç”¨é¦–é€‰** |
| **Plan-and-Execute** | æ­¥éª¤ä¼˜åŒ–ã€é«˜æ•ˆ | è®¡åˆ’å¯èƒ½å¤±æ•ˆ | è¾ƒé«˜ | å¤æ‚æµç¨‹ä»»åŠ¡ |
| **Reflexion** | é«˜è´¨é‡è¾“å‡º | è¿­ä»£æˆæœ¬é«˜ | å¾ˆé«˜ | ä»£ç /æ–‡ç« ç”Ÿæˆ |
| **Tree of Thoughts** | æ¢ç´¢å…¨é¢ | æ¶ˆè€—å¤§ã€æ…¢ | æé«˜ | åˆ›æ„/å†³ç­–ä»»åŠ¡ |
| **Chain** | ç®€å•ã€å¿«é€Ÿ | ä¸çµæ´» | ä½ | å›ºå®šæµç¨‹ |

---

## ğŸ› ï¸ åœ¨ä½ çš„ Agent Core ä¸­åº”ç”¨

### å½“å‰æ¶æ„æ˜ å°„

ä½ çš„ `agent_core` å·²ç»å…·å¤‡äº†å®ç° ReAct çš„åŸºç¡€ï¼š

```python
ä½ çš„ç»„ä»¶                    ReAct å¯¹åº”éƒ¨åˆ†
â”œâ”€â”€ LLMClient          â†’   Thought ç”Ÿæˆå™¨
â”œâ”€â”€ ToolCallHandler    â†’   Action æ‰§è¡Œå™¨
â”œâ”€â”€ MCP Client         â†’   Observation è·å–å™¨
â””â”€â”€ Orchestrator       â†’   æ•´ä½“å¾ªç¯æ§åˆ¶å™¨
```

### æ¨èå®ç°è·¯çº¿

#### Phase 1: å®ç°åŸºç¡€ ReAct (Zero-shot)

åˆ©ç”¨ OpenAI Function Callingï¼š

```python
# core/orchestrator.py
async def process_query(self, request: AgentRequest) -> AgentResponse:
    messages = [{"role": "user", "content": request.user_query}]
    tools = await self.mcp_client.get_tools()
    
    max_iterations = 5
    for i in range(max_iterations):
        # Thought (éšå¼) + Action
        response = await self.llm_client.chat_completion(
            messages=messages,
            tools=tools
        )
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å·¥å…·è°ƒç”¨
        if not response.get("tool_calls"):
            # æ²¡æœ‰æ›´å¤š Actionï¼Œä»»åŠ¡å®Œæˆ
            return self._build_response(response)
        
        # Observation: æ‰§è¡Œå·¥å…·
        tool_results = await self.tool_handler.execute_tools(
            response["tool_calls"]
        )
        
        # å°† Observation æ·»åŠ åˆ° messages
        messages.append({
            "role": "assistant",
            "content": response.get("content"),
            "tool_calls": response["tool_calls"]
        })
        for result in tool_results:
            messages.append({
                "role": "tool",
                "tool_call_id": result["id"],
                "content": json.dumps(result["output"])
            })
    
    raise MaxIterationError("è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°")
```

#### Phase 2: æ·»åŠ æ˜¾å¼ Thought (å¯é€‰)

å¦‚æœä½ æƒ³çœ‹åˆ° LLM çš„æ€è€ƒè¿‡ç¨‹ï¼š

```python
# ä¿®æ”¹ system prompt
system_prompt = """
You are a helpful assistant. When solving tasks:
1. First, explain your thinking (Thought)
2. Then, call the appropriate tool (Action)
3. After getting results (Observation), continue thinking

Format your thoughts as:
Thought: [your reasoning]
[then call tools if needed]
"""

# è§£æ LLM è¿”å›çš„ Thought
if "Thought:" in response["content"]:
    thought = extract_thought(response["content"])
    log.info("LLM Thought", thought=thought, request_id=request.id)
```

#### Phase 3: å®ç° Plan-and-Execute (è¿›é˜¶)

é€‚åˆä½ çš„ `EventRouter` æ¨¡å—ï¼š

```python
# core/event_router.py
async def plan_execution(self, query: str) -> ExecutionPlan:
    planning_prompt = f"""
    Create a step-by-step plan for: {query}
    
    Available tools: {self.tools}
    
    Return JSON:
    {{
        "steps": [
            {{"action": "tool_name", "reason": "why"}},
            ...
        ]
    }}
    """
    
    plan_response = await self.llm_client.chat_completion(
        messages=[{"role": "user", "content": planning_prompt}]
    )
    
    return ExecutionPlan.parse(plan_response)
```

---

## ğŸ“š æ¨èé˜…è¯»é¡ºåº

### ç¬¬ 1 å¤©: ç†è§£åŸºç¡€
1. **ReAct è®ºæ–‡**: https://arxiv.org/abs/2210.03629
   - é‡ç‚¹è¯» Section 3 (Method) å’Œ Figure 2
   - æ—¶é—´: 1 å°æ—¶

2. **OpenAI Function Calling æ–‡æ¡£**:
   - https://platform.openai.com/docs/guides/function-calling
   - æ—¶é—´: 30 åˆ†é’Ÿ

### ç¬¬ 2 å¤©: çœ‹å®ç°
3. **LangChain ReAct Agent æºç **:
   - https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/agents/react/agent.py
   - é‡ç‚¹çœ‹ `_get_action_and_input()` æ–¹æ³•
   - æ—¶é—´: 1 å°æ—¶

4. **åŠ¨æ‰‹å®éªŒ**: åœ¨ä½ çš„ `agent_core` ä¸­å®ç°æœ€ç®€ ReAct å¾ªç¯
   - æ—¶é—´: 2-3 å°æ—¶

### ç¬¬ 3 å¤©: è¿›é˜¶èŒƒå¼
5. **Plan-and-Execute**:
   - LangChain æ–‡æ¡£: https://python.langchain.com/docs/use_cases/more/agents/plan_and_execute
   - æ—¶é—´: 1 å°æ—¶

6. **Reflexion è®ºæ–‡**: https://arxiv.org/abs/2303.11366
   - é€‰è¯»ï¼Œäº†è§£è‡ªæˆ‘åæ€æœºåˆ¶
   - æ—¶é—´: 1 å°æ—¶

---

## ğŸ“ å®æˆ˜ç»ƒä¹ 

### ç»ƒä¹  1: æ‰‹åŠ¨æ¨¡æ‹Ÿ ReAct
ç”¨çº¸ç¬”æ¨¡æ‹Ÿè§£å†³è¿™ä¸ªä»»åŠ¡ï¼š
```
ä»»åŠ¡: "å¸®æˆ‘æŸ¥åŒ—äº¬æ˜å¤©å¤©æ°”ï¼Œå¦‚æœä¼šä¸‹é›¨å°±æé†’æˆ‘å¸¦ä¼"

å¯ç”¨å·¥å…·:
- get_weather(city, date)
- send_reminder(message)

å†™å‡ºå®Œæ•´çš„ Thought-Action-Observation è¿‡ç¨‹
```

### ç»ƒä¹  2: å¯¹æ¯”ä¸åŒèŒƒå¼
åŒä¸€ä¸ªä»»åŠ¡ç”¨ 3 ç§èŒƒå¼å®ç°ï¼š
```
ä»»åŠ¡: "å¸®æˆ‘å‡†å¤‡ä¸€ä»½å…³äº AI çš„æ¼”è®²ç¨¿"

1. ReAct ç‰ˆæœ¬
2. Plan-and-Execute ç‰ˆæœ¬
3. Reflexion ç‰ˆæœ¬

å¯¹æ¯” token æ¶ˆè€—å’Œè´¨é‡
```

### ç»ƒä¹  3: åœ¨ agent_core ä¸­å®ç°
```python
# åœ¨ä½ çš„é¡¹ç›®ä¸­å®ç°ä¸€ä¸ªå®Œæ•´çš„ ReAct å¾ªç¯
# æ”¯æŒè¿™ä¸ªæŸ¥è¯¢:
query = "æŸ¥è¯¢åŒ—äº¬æ˜å¤©å¤©æ°”ï¼Œå¦‚æœé€‚åˆæˆ·å¤–è¿åŠ¨å°±æ¨è3ä¸ªæ´»åŠ¨"

# é¢„æœŸè¡Œä¸º:
# Iteration 1: call get_weather("åŒ—äº¬", "æ˜å¤©")
# Iteration 2: åŸºäºå¤©æ°”ç»“æœï¼Œcall search_activities("æˆ·å¤–è¿åŠ¨", "åŒ—äº¬")
# Iteration 3: è¿”å›æœ€ç»ˆç­”æ¡ˆ
```

---

## ğŸ’¡ å…³é”®è¦ç‚¹æ€»ç»“

1. **ReAct æ˜¯æœ€é€šç”¨çš„èŒƒå¼**ï¼Œé€‚åˆ 90% çš„åœºæ™¯
2. **OpenAI Function Calling æ˜¯ç®€åŒ–çš„ ReAct**ï¼Œéšè—äº† Thought
3. **ä½ çš„ agent_core å·²ç»å…·å¤‡å®ç° ReAct çš„åŸºç¡€**
4. **ä»ç®€å•å¼€å§‹**: å…ˆå®ç° Zero-shot ReActï¼Œå†è€ƒè™‘ä¼˜åŒ–
5. **å¯è§‚æµ‹æ€§å¾ˆé‡è¦**: è®°å½•æ¯æ¬¡ Thought/Action/Observationï¼Œæ–¹ä¾¿è°ƒè¯•

---

## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

- [ ] é˜…è¯» ReAct è®ºæ–‡ Section 3
- [ ] åœ¨ `orchestrator.py` ä¸­å®ç°åŸºç¡€ ReAct å¾ªç¯
- [ ] æµ‹è¯•ä¸€ä¸ªéœ€è¦ 2-3 è½®å·¥å…·è°ƒç”¨çš„ä»»åŠ¡
- [ ] æ·»åŠ æ—¥å¿—è®°å½•æ¯æ¬¡è¿­ä»£çš„è¿‡ç¨‹
- [ ] é‡åˆ°é—®é¢˜éšæ—¶å›æ¥è®¨è®ºï¼

Good luck! ğŸ’ª